{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eihwood/ML-Lab/blob/main/DL_in_Pytorch_Crash_Course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![logo.jpeg](data:image/jpeg;base64,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)\n",
        "\n",
        "Welcome to NYC Data Science Academy Crash Course.\n",
        "\n",
        "NYC Data Science Academy’s mission is to provide accelerated data science training programs that prepare people for employment as data science professionals and to offer continuing education courses for professional development. We have trained thousands of data science professioals and assisted them to land a job in the field. Check out our job outcomes from https://nycdatascience.com/our-outcome/"
      ],
      "metadata": {
        "id": "gCTkROZuITbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "This is meant to be a fast paced introduction to machine learning using Pytorch. The goal is to get familiar with the basic aspects of building a model and train it on a supervised learning task."
      ],
      "metadata": {
        "id": "rM-dddGFIpqN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEBP4KOUiYe8"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors\n",
        "\n",
        "[Tensors](https://pytorch.org/docs/stable/tensors.html) are (multidimensional) arrays, and are the core data type used in deep learning."
      ],
      "metadata": {
        "id": "fvV-soUFifAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new tensor out of existing data\n",
        "t = torch.tensor([1,3,3,7])\n",
        "print(t)\n",
        "# get the the dimensions of a tensor\n",
        "print(t.size())\n",
        "# initialize a tensor of all ones of a particular size\n",
        "t = torch.ones(2, 3, 4)\n",
        "print(t)\n",
        "# `torch.Size` can be unpacked\n",
        "depth, height, width = t.size()\n",
        "print('depth:', depth, 'height:', height, 'width:', width)\n",
        "# tensors can be addressed just like numpy arrays\n",
        "print(t[0].size())\n",
        "# random, normally distributed tensors of a given size are also easy\n",
        "t = torch.randn(2,3)\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjqmeHYYiySh",
        "outputId": "df6a1878-f347-4ee8-b3d7-4e257eb3c4fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 3, 3, 7])\n",
            "torch.Size([4])\n",
            "tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n",
            "depth: 2 height: 3 width: 4\n",
            "torch.Size([3, 4])\n",
            "tensor([[ 0.0727, -0.5302,  2.2051],\n",
            "        [-0.0480, -0.2511, -0.9623]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modules\n",
        "\n",
        "Torch uses [Modules](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) as the brimary building block for models. A `Module` can represent a layer or an entire model (models can be used as layers within other models).\n",
        "\n",
        "[torch.nn](https://pytorch.org/docs/stable/nn.html) is the primary library defining the most comong building blocks for most neural networks."
      ],
      "metadata": {
        "id": "66SVp7_TlEpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all basic layers/modules are defined in torch.nn\n",
        "import torch.nn as nn\n",
        "\n",
        "# a `Linear` layer (also called fully connected, or `Dense` in Keras)\n",
        "# is just y = Wx + b. `Linear` takes the input dimension, output dimensions\n",
        "# whether or not to include a bias term (default True)\n",
        "m = nn.Linear(2, 3)\n",
        "print(m)\n",
        "print('weight matrix:', m.weight.size())\n",
        "print('bias vector', m.bias.size())\n",
        "# you can create one without a bias as well\n",
        "m = nn.Linear(2, 3, bias=False)\n",
        "print(m)\n",
        "print('weight matrix:', m.weight.size())\n",
        "print('bias vector', m.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92QW7Vn_lE6t",
        "outputId": "1de71a97-f92e-4ed0-f11a-ba0d9eab6e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=2, out_features=3, bias=True)\n",
            "weight matrix: torch.Size([3, 2])\n",
            "bias vector torch.Size([3])\n",
            "Linear(in_features=2, out_features=3, bias=False)\n",
            "weight matrix: torch.Size([3, 2])\n",
            "bias vector None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Model: Multilayer Perceptron\n",
        "\n",
        "We'll define a simple multilayer perceptron ([MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron) a.k.a. feedforward network) with one hidden layer. This will be a subclass of `torch.nn.Module`, which requires:\n",
        "* `__init__` with a call to `super().__init__()`\n",
        "* `forward()` which defines how to run the model given an input\n",
        "\n",
        "We will use the container [torch.nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential) to glue all of our layers into a single module that passes the output from the previous step as the input to the next. Note that you must ensure that the output dimensions of the previous layer match the input dimensions of the next.\n",
        "\n",
        "The main component which makes neural networks able to learn non-linear functions are the [activations](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity) places between the various layers. Since this model is very small and simple, we will be using [torch.nn.Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid), which produces an \"S curve\" that squashes all values to the range 0.0 - 1.0."
      ],
      "metadata": {
        "id": "wufDKTo7xrL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(self.input_dim, self.hidden_dim),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(self.hidden_dim, self.output_dim),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # the `Sequential` can just be called on the input\n",
        "    return self.fc(x)"
      ],
      "metadata": {
        "id": "-fKJ3Gtgxrdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Device\n",
        "\n",
        "Torch supports multiple backends, most notibly `'cpu'` and `'cuda'` (with experimental support for Apple Metal as well). The main thing to remember is that all `Module`s and `Tensor`s neeed to be on the same device when running, or else you will get an error. Also note that all everything initially begins on CPU when created (with the exception of models that were saved while on GPU, but let's ignore that for now)."
      ],
      "metadata": {
        "id": "Df_tjsw9nJ7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the device we are using and save it for later. change the runtime\n",
        "# to GPU to see if print `cuda`\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "# create a tensor and send it to our device\n",
        "x = torch.randn(2,3, device=device)\n",
        "print(x)\n",
        "# you can also send things to a device after they are creates\n",
        "x = torch.randn(2, 3)\n",
        "print(x)\n",
        "x = x.to(device)\n",
        "print(x)\n",
        "\n",
        "# some operations, such as converting to a numpy array, require tensors\n",
        "# to be on the CPU specifically, so using `.cpu()` is helpful\n",
        "print(x.cpu().numpy())\n",
        "# there is also `.cuda()` but that asumesthat you actually have a GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "a8XWWwmxnKEs",
        "outputId": "25d7b02f-b46c-4f03-e8ae-91d457965169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3da3f288bdb2>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# create a tensor and send it to our device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "The primary mechanisms for working with data live in [torch.utils.data](https://pytorch.org/docs/stable/data.html).\n",
        "\n",
        "Now we will make a model that solves [XOR](https://en.wikipedia.org/wiki/Exclusive_or). This will require creating:\n",
        "* a [map-style](https://pytorch.org/docs/stable/data.html#map-style-datasets) `Dataset` to hold our examples\n",
        "* a model to train\n",
        "* a training loop\n",
        "\n",
        "Although simple, XOR is useful as it requires a model that can handle non-linear relationships between inputs and outputs: it is not possible to draw a single straight line as a decision boundary."
      ],
      "metadata": {
        "id": "2iWUuzShp2a4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "a `Dataset` is an interface for defining data to train on. it requires defining\n",
        "* __init__\n",
        "* __len__ to return the number of training examples\n",
        "* __getitem__ to return an example at a specific index\n",
        "'''\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class XorDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    # example inputs\n",
        "    self.x = [\n",
        "        [0, 0],\n",
        "        [1, 0],\n",
        "        [0, 1],\n",
        "        [1, 1]\n",
        "    ]\n",
        "    # example outputs\n",
        "    self.y = [\n",
        "        0,\n",
        "        1,\n",
        "        1,\n",
        "        0\n",
        "    ]\n",
        "  \n",
        "  def __len__(self):\n",
        "    # return the number of training examples\n",
        "    return len(self.x)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    # return the input/output for a given example (by index)\n",
        "    x = self.x[idx]\n",
        "    y = self.y[idx]\n",
        "    return {'x': torch.FloatTensor(x), 'y': torch.FloatTensor([y])}\n",
        "\n",
        "xor_dataset = XorDataset()\n",
        "print(xor_dataset[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TK2NUybp2nY",
        "outputId": "46e970c0-317b-4ccc-90de-58ea7429e270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x': tensor([0., 1.]), 'y': tensor([1.])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader and Batching\n",
        "\n",
        "The most common way to work with a `Dataset` is to use a [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). This handles things like:\n",
        "* iterating through the `Dataset`\n",
        "* optionally randomizing the order of examples\n",
        "* batching examples together\n",
        "\n",
        "Batching (a.k.a. mini-batches) means loading multiple training examples in *parallel*. This is helpful, especially when using GPUs, for being able to do more computation in a single pass, speeding up traning for feedforward models. Additionally some objectives like contrastive learning specifically rely on batcfhing as part of the loss function. However recurrent models benefit less from batching as they take sequences as input, which often requires padding shorter examples since everything in the batch needs to be the same length."
      ],
      "metadata": {
        "id": "PCkwVhLqsNyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "dataloader = DataLoader(xor_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "for batch in dataloader:\n",
        "  x = batch['x']\n",
        "  y = batch['y']\n",
        "  print(x, 'x.size()', x.size())\n",
        "  print(y, 'y.size()', y.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2GwzQWRsOiE",
        "outputId": "3f17698e-8ce0-477a-de78-1ea7074c69c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 1.]]) x.size() torch.Size([3, 2])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [0.]]) y.size() torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Setup\n",
        "\n",
        "For supervised learning, we need:\n",
        "* a model to train\n",
        "* a dataset\n",
        "* an [optimizer](https://pytorch.org/docs/stable/optim.html)\n",
        "* an objective ([loss function](https://pytorch.org/docs/stable/nn.html#loss-functions))\n",
        "\n",
        "We then loop over all of our training data multiple times (epochs) and track the loss so that we can see how the model is improving. Of course you can (and usually should) also track validation loss on your test data, but we will omit that here.\n",
        "\n",
        "Here we will be using the [Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam) optimizer and [mean squared error loss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss)."
      ],
      "metadata": {
        "id": "rZX3m03zvwp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "from tqdm import trange  # gives us a nice progress bar\n",
        "\n",
        "epochs = 5000  # the number of times to iterate through the training data\n",
        "\n",
        "model = MLP(2, 2, 1)  # create an instance of our model\n",
        "model = model.to(device)  # send the model to the appropriate device\n",
        "print(model.train())  # set the model to train mode (default) and print it for good measure\n",
        "opt = Adam(model.parameters())  # initialize the optimizer with the model parameters\n",
        "loss_fn = nn.MSELoss()  # create an instance of our loss function\n",
        "losses = []  # create an empty list for tracking the loss every epoch\n",
        "\n",
        "for epoch in trange(epochs):  # loop for the number of epochs\n",
        "  for batch in dataloader:  # iterate through the dataset\n",
        "  \n",
        "    # get the inputs and target outputs and send them to the device\n",
        "    x = batch['x'].to(device)\n",
        "    y = batch['y'].to(device)\n",
        "\n",
        "    # run the model and get its prediction\n",
        "    y_hat = model(x)\n",
        "\n",
        "    # calculate the loss\n",
        "    loss = loss_fn(y_hat, y)\n",
        "\n",
        "    # clear the previous gradient from the optimizer\n",
        "    opt.zero_grad()\n",
        "    # calculate the gradient based on the loss\n",
        "    loss.backward()\n",
        "    # update the model weights based on the gradient\n",
        "    opt.step()\n",
        "\n",
        "    '''\n",
        "    Store the loss in a list so that we can plot it later.\n",
        "    When doing so however, we need to call `.detach()` in\n",
        "    order to remove the gradient, `.cpu()` to make sure it\n",
        "    is on the CPU, and `.numpy()` to convert it into a numpy\n",
        "    value because matplotlib doesn't work directly on tensors.\n",
        "    '''\n",
        "    losses.append(loss.detach().cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV-3ISDbsjmO",
        "outputId": "88174f35-190d-4bda-b60e-3f4df40d4bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=2, out_features=1, bias=True)\n",
            "    (3): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:11<00:00, 418.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "plvMl6o6zMSe",
        "outputId": "c9bcd62b-42d3-428e-d1d2-f177396e07ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our training data is so small, we can iterate through all examples and compare the prediction to the target. For more complex datasets/tasks could use a test set to plot the validation loss, calculate a confusion matrix, etc."
      ],
      "metadata": {
        "id": "uWIj3DeKgbVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.cpu()\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for example in xor_dataset:\n",
        "    x = example['x']\n",
        "    y = example['y']\n",
        "    y_hat = model(x) \n",
        "    loss = loss_fn(y_hat, y)\n",
        "    print('x:', x, 'y:', y, 'y_hat:', y_hat, 'loss:', loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnFPlJUBz4pe",
        "outputId": "b390a45f-5e1f-4efc-d2e4-f6caf15a572e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tensor([0., 0.]) y: tensor([0.]) y_hat: tensor([0.1744]) loss: tensor(0.0304)\n",
            "x: tensor([1., 0.]) y: tensor([1.]) y_hat: tensor([0.8192]) loss: tensor(0.0327)\n",
            "x: tensor([0., 1.]) y: tensor([1.]) y_hat: tensor([0.8135]) loss: tensor(0.0348)\n",
            "x: tensor([1., 1.]) y: tensor([0.]) y_hat: tensor([0.2047]) loss: tensor(0.0419)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus 1: Convolution Layer Overview\n",
        "\n",
        "One of the most important early developments in deep learning was [convolutional neural networks](https://en.wikipedia.org/wiki/Convolutional_neural_network). The basic idea is that you can sweep a small window (called a kernel) across an input in order to extract higher level features useful for downstream processing. 2D Convolution has been extremely important in computer vision, but the same exact approach works in 1D (e.g. time series), and 3D (either three spatial dimensions or 2D + time). Pytorch implements these in the [torch.nn library](https://pytorch.org/docs/stable/nn.html#convolution-layers) we saw earlier.\n",
        "\n",
        "The idea is that you define a small patch of learnable weights that will be **shared** across all spatial locations of the input. This is opposed to a `Linear` (fully connected) layer which learns a single set of weights for the entire input. As a result, convolutions allow for learning *local* or *translationally invariant* features, whereas fully connected layers learn *global* features. This is helpful in vision because \"a 7 is a 7 regardless of where in the image it appears.\" [Here](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53) is a good overview of convolution in general.\n",
        "\n",
        "Since convolutions learn to extract features from small patches, it is usually required to stack multiple layers in sequence in order to learn more complex features. One common architecture is called a Residual Network (ResNet for short) allows for stable training of very deep convolutionl networks. [Here](https://towardsdatascience.com/residual-network-implementing-resnet-a7da63c7b278) is good walkthrough of how to implement one Pytorch."
      ],
      "metadata": {
        "id": "5KrgLuKng9W-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kernels\n",
        "\n",
        "The learnable parameters of a convolution are its kernel. Specifically in the 2D (image) case, a kernel has four dimensions:\n",
        "* the width of the patch\n",
        "* the height of the patch\n",
        "* the number of **input channels**\n",
        "* the number of **output channels**\n",
        "Beyond that, the convolution layer itself can optionally define things like `stride` (the number of steps to move by in the x/y dimension), `dilation` (the number of steps to skip **between** each row/column of the kernel), but for now we will ignore those.\n",
        "\n",
        "Width and height are exactly what they sound like. Channels however are more abstract. For an input image, there are typically either one (for grayscale) or three (for color) channels. In intermediate layers the number of channels represents the number of unique feature maps the layer can represent. Typically this increases as you go deeper into the network. It is worth noting that the relationship between *input* and *output* channels is exactly the same as a `Linear` layer (see [1x1 convolutions](https://towardsdatascience.com/1x1-convolution-5219bbc09027/) for a more in-depth explanation)."
      ],
      "metadata": {
        "id": "HQK_keXUmmXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "channels = 3  # red, green, blue\n",
        "height = width = 28\n",
        "x = torch.randn(batch_size, channels, height, width)\n",
        "print('original input size:', x.size())\n",
        "\n",
        "l = nn.Conv2d(channels, 16, 3, bias=False)  # 3x3 kernel, 3 input channels, 16 output channels\n",
        "print(l.eval())\n",
        "z = l(x)\n",
        "# note that the channel dimension is now 16 and the width/height has reduced by 2\n",
        "print('size after convolution', z.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN4KMluOmGlJ",
        "outputId": "86469c73-926a-4ed4-99fe-7a3c6066c0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original input size: torch.Size([1, 3, 28, 28])\n",
            "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "size after convolution torch.Size([1, 16, 26, 26])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus 2: Recurrent Layer Overview\n",
        "\n",
        "So far we have seen `Linear` layers, which have a fixed input dimension, and convolution layers, which slide a fixed size window over their input. Both of these work on fixed-length inputs. While they can process larger inputs in the form of batches, each example is processed in parallel and no information can be shared between them. For some use cases, such as fixed size images or a known set of coumns in a record, this is perfectly fine. However when working with time series data (which includes text) we often do not know the input length ahead of time, or it is generally variable. While we can decide on some maximum sequence length and pad shorter inputs, it would be nice if we could take sequences of arbitrary length as an input directly. This is exactly what **Recurrent Neural Networks** (RNNs) are for.\n",
        "\n",
        "RNNs work based on two inputs: the current sequence value and a *hidden state*. Hidden state is just a fancy name for memory, which is a vector that we use to store information from previous inputs. The basic pseudo code using an RNN is:\n",
        "\n",
        "```python\n",
        "h = torch.zeros(...)\n",
        "for x in inputs:\n",
        "  h = rnn(x, h)\n",
        "# do something with h\n",
        "```\n",
        "\n",
        "The main advantage of RNNs is that they can (theoretically at lease) handle arbitrarily long sequences. In reality there is a practical limit to how much they can remember based on (at least) two major factors:\n",
        "\n",
        "* vanishing/exploding gradients making it difficult to train on longer sequences (addressed by [LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM) and [GRU](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU/))\n",
        "* the fact that the hidden state is a fixed size, only offering finite memory capacity\n",
        "\n",
        "One other thing to keep in mind is that since RNNs process inputs sequentially they are inherently sequential and thus do not benefit nearly as much from GPUs (although they can still be trained on batches, provided all inputs are padded to be the same length).\n",
        "\n",
        "A classic (yet dated) blog post by Andrej Karpathy is [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). Even though things have changed quite a lot since it was written, it is still a good overview of some of the uses for RNNs."
      ],
      "metadata": {
        "id": "0W-Ek94fteoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus 3: Transformers Overview\n",
        "\n",
        "Since 2017, the deep learning world has been taken by storm with the advent of the Transformer. First proposed in the paper [Attention is All You Need](https://arxiv.org/abs/1706.03762) by researchers at Google Brain (but really in [Using Fast Weights to Attend to the Recent Past](https://arxiv.org/abs/1610.06258), and really really in [1991 by Jürgen Schmidhuber](https://people.idsia.ch/~juergen/fast-weight-programmer-1991-transformer.html)), the Transformer has basically become state of the art in most things. Most notibly with models like [BERT](https://en.wikipedia.org/wiki/BERT_(language_model)), the [GPT](https://en.wikipedia.org/wiki/Generative_pre-trained_transformer) series, Vision Transformer ([ViT](https://arxiv.org/abs/2010.11929)), among others.\n",
        "\n",
        "The main thing to know about transformers is that they operate on **sets**. Often you hear about them being used on sequences, which requires applying [positional encoding](https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/) to the input. They also have a **fixed** input size, making them less flexible compared to RNNs, however due to the attention mechanism they are able to pass information between *any* part of the input to any other part, rather than being forced to only propegate information forward through the sequence."
      ],
      "metadata": {
        "id": "UlMBB70z0Umu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus 4: Other Resources\n",
        "\n",
        "* [Andrej Karpathy](https://www.youtube.com/@AndrejKarpathy)'s Youtube Channel where he is currently building a minimal implementation of Pytorch from the ground up\n",
        "* [Yannic Kilcher](https://www.youtube.com/@YannicKilcher)'s Youtube channel where he has overviews of tons of papers, streams working on open source projects, and keeps up with current events in ML\n",
        "* [lucidrains](https://github.com/lucidrains) on github who implements absolutely everything"
      ],
      "metadata": {
        "id": "zv10mtUy20HY"
      }
    }
  ]
}